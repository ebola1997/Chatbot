{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e521d5fb-d1fa-4896-b90d-c6d4a9a52d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15dcdfd5-5c82-4f1b-85a2-6278776346d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca file TXT\n",
    "def read_txt(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        return f.read()\n",
    "\n",
    "# Membaca file PDF\n",
    "def read_pdf(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        pdf_reader = PyPDF2.PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "# Membaca file DOCX\n",
    "def read_docx(filename):\n",
    "    doc = Document(filename)\n",
    "    text = \"\\n\".join(paragraph.text for paragraph in doc.paragraphs)\n",
    "    return text\n",
    "\n",
    "# Mendapatkan paragraf dari semua file\n",
    "def parse_file(filename):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        content = read_txt(filename)\n",
    "    elif filename.endswith(\".pdf\"):\n",
    "        content = read_pdf(filename)\n",
    "    elif filename.endswith(\".docx\"):\n",
    "        content = read_docx(filename)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {filename}\")\n",
    "    \n",
    "    paragraphs = []\n",
    "    buffer = []\n",
    "    for line in content.splitlines():\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            buffer.append(line)\n",
    "        elif len(buffer):\n",
    "            paragraphs.append(\" \".join(buffer))\n",
    "            buffer = []\n",
    "    if len(buffer):\n",
    "        paragraphs.append(\" \".join(buffer))\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12ee8eb-e1d2-4014-9c1e-f2ee07ad8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendapatkan paragraf dari semua file\n",
    "def parse_file(filename):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        content = read_txt(filename)\n",
    "    elif filename.endswith(\".pdf\"):\n",
    "        content = read_pdf(filename)\n",
    "    elif filename.endswith(\".docx\"):\n",
    "        content = read_docx(filename)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {filename}\")\n",
    "    \n",
    "    paragraphs = []\n",
    "    buffer = []\n",
    "    for line in content.splitlines():\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            buffer.append(line)\n",
    "        elif len(buffer):\n",
    "            paragraphs.append(\" \".join(buffer))\n",
    "            buffer = []\n",
    "    if len(buffer):\n",
    "        paragraphs.append(\" \".join(buffer))\n",
    "    return paragraphs\n",
    "\n",
    "# Simpan embedding ke file\n",
    "def save_embeddings(filename, embeddings):\n",
    "    if not os.path.exists(\"embeddings\"):\n",
    "        os.makedirs(\"embeddings\")\n",
    "    with open(f\"embeddings/{filename}.json\", \"w\") as f:\n",
    "        json.dump(embeddings, f)\n",
    "\n",
    "# Memuat embedding dari file\n",
    "def load_embeddings(filename):\n",
    "    if not os.path.exists(f\"embeddings/{filename}.json\"):\n",
    "        return False\n",
    "    with open(f\"embeddings/{filename}.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Mendapatkan embedding\n",
    "def get_embeddings(filename, modelname, chunks):\n",
    "    if (embeddings := load_embeddings(filename)) is not False:\n",
    "        return embeddings\n",
    "    embeddings = [\n",
    "        ollama.embeddings(model=modelname, prompt=chunk)[\"embedding\"]\n",
    "        for chunk in chunks\n",
    "    ]\n",
    "    save_embeddings(filename, embeddings)\n",
    "    return embeddings\n",
    "\n",
    "# Cosine similarity untuk menemukan kemiripan\n",
    "def find_most_similar(needle, haystack):\n",
    "    needle_norm = norm(needle)\n",
    "    similarity_scores = [\n",
    "        np.dot(needle, item) / (needle_norm * norm(item)) for item in haystack\n",
    "    ]\n",
    "    return sorted(zip(similarity_scores, range(len(haystack))), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3016466c-83b8-48c4-a5fc-91cc47408156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.post(\"http://localhost:11434/api/chat\", json={\n",
    "                    \"model\": \"llama3\",\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": \"nama saya adalah teguh prasetyo umur 25 tahun, pekerjaan dba\" ,\n",
    "                        },\n",
    "                        {\"role\": \"user\", \"content\": \"siapa teguh?\"},\n",
    "                    ]\n",
    "                })\n",
    "    print(response.json())\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfddf26-5b61-444b-b73e-c7c0bc144a7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# response = requests.post(\"http://localhost:11434/api/generate\", json={\"model\": \"llama3\", \"prompt\": \"what is AI?\"})\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse Status Code:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mresponse\u001b[49m\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse Content-Type:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/x-ndjson\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # response = requests.post(\"http://localhost:11434/api/generate\", json={\"model\": \"llama3\", \"prompt\": \"what is AI?\"})\n",
    "    \n",
    "    print(\"Response Status Code:\", response.status_code)\n",
    "    print(\"Response Content-Type:\", response.headers.get('Content-Type'))\n",
    "\n",
    "    if response.headers.get('Content-Type') == 'application/x-ndjson':\n",
    "        print(\"Response is in NDJSON format.\")\n",
    "        \n",
    "        full_response = \"\"  # Initialize an empty string to hold the full response\n",
    "        \n",
    "        for line in response.text.splitlines():\n",
    "            try:\n",
    "                # Parse each line as a JSON object\n",
    "                json_data = json.loads(line)\n",
    "                \n",
    "                # Append the 'response' part of each JSON object to the full response\n",
    "                full_response += json_data['response']\n",
    "                \n",
    "                # If the response is complete, print the full response\n",
    "                if json_data.get('done'):\n",
    "                    print(\"Full Response:\", full_response)\n",
    "                    break\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing line: {line}\")\n",
    "                print(f\"JSONDecodeError: {e}\")\n",
    "    else:\n",
    "        print(\"Response is not in NDJSON format.\")\n",
    "        print(response.json())\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c596731c-4396-4382-a701-9b74620663cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  hai bot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Error during request: Extra data: line 2 column 1 (char 120)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the assistant. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"Anda adalah asisten yang membantu menjawab pertanyaan dengan bahasa Indonesia \n",
    "dan berdasarkan cuplikan teks yang diberikan dalam konteks. Jawab hanya menggunakan konteks yang disediakan, \n",
    "menjadi sesingkat mungkin. Jika Anda tidak yakin, katakan saja Anda tidak tahu.\n",
    "Context:\n",
    "\"\"\"\n",
    "\n",
    "data_folder = \"data\"\n",
    "all_paragraphs = []\n",
    "filenames = []\n",
    "\n",
    "# Function to parse files (You need to implement this or use an existing function)\n",
    "def parse_file(file_path):\n",
    "    # Parse the file and return paragraphs (implement your file parsing logic here)\n",
    "    return []\n",
    "\n",
    "# Function to get embeddings (using requests instead of ollama)\n",
    "def get_embeddings(modelname, chunks):\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                \"http://localhost:11434/api/embeddings\",  # Use the correct endpoint here\n",
    "                json={\"model\": modelname, \"prompt\": chunk}\n",
    "            )\n",
    "            response.raise_for_status()  # Ensure we raise an error for bad status codes\n",
    "            embeddings.append(response.json()[\"embedding\"])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching embeddings: {e}\")\n",
    "            embeddings.append(None)  # Append None or handle this error gracefully\n",
    "    return embeddings\n",
    "\n",
    "# Function to find the most similar chunks (implement your similarity search here)\n",
    "def find_most_similar(prompt_embedding, embeddings):\n",
    "    # Implement your similarity function here\n",
    "    return []\n",
    "\n",
    "def main():\n",
    "    global all_paragraphs, filenames\n",
    "\n",
    "    # Iterasi semua file dalam folder data\n",
    "    for file in os.listdir(data_folder):\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        if file.lower().endswith((\".txt\", \".pdf\", \".docx\")):\n",
    "            paragraphs = parse_file(file_path)\n",
    "            all_paragraphs.extend(paragraphs)\n",
    "            filenames.append(file)\n",
    "\n",
    "    # Create embeddings manually using requests\n",
    "    embeddings = get_embeddings(\"nomic-embed-text\", all_paragraphs)\n",
    "\n",
    "    while True:\n",
    "        prompt = input(\"Silakan tanya bosku? (ketik 'exit' untuk keluar) -> \")\n",
    "\n",
    "        if prompt.lower() == \"exit\":\n",
    "            print(\"Exiting the assistant. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            # Manually fetch the prompt embedding using requests\n",
    "            prompt_response = requests.post(\n",
    "                \"http://localhost:11434/api/embeddings\",  # Use the correct endpoint here\n",
    "                json={\"model\": \"nomic-embed-text\", \"prompt\": prompt}\n",
    "            )\n",
    "            prompt_response.raise_for_status()  # Ensure we raise an error for bad status codes\n",
    "            prompt_embedding = prompt_response.json()[\"embedding\"]\n",
    "            \n",
    "            most_similar_chunks = find_most_similar(prompt_embedding, embeddings)[:5]\n",
    "\n",
    "            # Get the chat response manually\n",
    "            chat_response = requests.post(\n",
    "                \"http://localhost:11434/api/chat\",  # Use the correct endpoint here\n",
    "                json={\n",
    "                    \"model\": \"llama3\",\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": SYSTEM_PROMPT + \"\\n\".join(all_paragraphs[item[1]] for item in most_similar_chunks),\n",
    "                        },\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "            if chat_response.status_code != 200:\n",
    "                print(f\"Error: Received {chat_response.status_code} response\")\n",
    "                print(f\"Response content: {chat_response.text}\")\n",
    "            else:\n",
    "                print(\"\\n\\n\")\n",
    "                print(chat_response.json()[\"message\"][\"content\"])\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error during request: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80dbed1d-4d56-4d28-89d8-a3ba1e46037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# URL untuk API Ollama, ganti sesuai dengan alamat API Anda\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/\"\n",
    "\n",
    "# Fungsi untuk request embeddings\n",
    "def get_embeddings_from_ollama(modelname, chunk):\n",
    "    response = requests.post(\n",
    "        OLLAMA_API_URL + \"embeddings\",\n",
    "        json={\"model\": modelname, \"prompt\": chunk},\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"embedding\"]\n",
    "\n",
    "# Fungsi untuk request chat (LLM) response\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Fungsi untuk request chat (LLM) response\n",
    "def chat_with_ollama(model, messages):\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            OLLAMA_API_URL + \"chat\",\n",
    "            json={\"model\": model, \"messages\": messages},\n",
    "        )\n",
    "        \n",
    "        if response.headers.get('Content-Type') == 'application/x-ndjson':\n",
    "            # print(\"Response is in NDJSON format.\")\n",
    "            \n",
    "            full_response = \"\"  # Initialize an empty string to hold the full response\n",
    "            \n",
    "            for line in response.text.splitlines():\n",
    "                try:\n",
    "                    # Parse each line as a JSON object\n",
    "                    json_data = json.loads(line)\n",
    "                    \n",
    "                    # Print the entire json_data to inspect its structure\n",
    "                    # print(\"Parsed JSON Data:\", json_data)\n",
    "                    \n",
    "                    # Check if 'message' key exists and contains 'content'\n",
    "                    if 'message' in json_data and 'content' in json_data['message']:\n",
    "                        # Append the 'content' part of each 'message' to the full response\n",
    "                        full_response += json_data['message']['content']\n",
    "                        \n",
    "                        # If the response is complete, break out of the loop\n",
    "                        if json_data.get('done'):\n",
    "                            break\n",
    "                    else:\n",
    "                        print(\"No 'message' or 'content' key in this JSON object:\", json_data)\n",
    "                \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing line: {line}\")\n",
    "                    print(f\"JSONDecodeError: {e}\")\n",
    "        \n",
    "            # Return the full response after the loop ends\n",
    "            return full_response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during request: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# Membaca file TXT\n",
    "def read_txt(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        return f.read()\n",
    "\n",
    "# Membaca file PDF\n",
    "def read_pdf(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        pdf_reader = PyPDF2.PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "# Membaca file DOCX\n",
    "def read_docx(filename):\n",
    "    doc = Document(filename)\n",
    "    text = \"\\n\".join(paragraph.text for paragraph in doc.paragraphs)\n",
    "    return text\n",
    "\n",
    "# Mendapatkan paragraf dari semua file\n",
    "def parse_file(filename):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        content = read_txt(filename)\n",
    "    elif filename.endswith(\".pdf\"):\n",
    "        content = read_pdf(filename)\n",
    "    elif filename.endswith(\".docx\"):\n",
    "        content = read_docx(filename)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {filename}\")\n",
    "    \n",
    "    paragraphs = []\n",
    "    buffer = []\n",
    "    for line in content.splitlines():\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            buffer.append(line)\n",
    "        elif len(buffer):\n",
    "            paragraphs.append(\" \".join(buffer))\n",
    "            buffer = []\n",
    "    if len(buffer):\n",
    "        paragraphs.append(\" \".join(buffer))\n",
    "    return paragraphs\n",
    "\n",
    "# Mendapatkan embedding\n",
    "def get_embeddings(filename, modelname, chunks):\n",
    "    embedding_file_path = f\"embeddings/{filename}.json\"\n",
    "    \n",
    "    # Check if the embedding file already exists\n",
    "    if os.path.exists(embedding_file_path):\n",
    "        print(f\"Embedding file {filename}.json already exists. Loading embeddings...\")\n",
    "        # Load the embeddings from the existing file\n",
    "        with open(embedding_file_path, \"r\") as f:\n",
    "            embeddings = json.load(f)\n",
    "    else:\n",
    "        print(f\"Embedding file {filename}.json not found. Generating new embeddings...\")\n",
    "        # If file doesn't exist, generate embeddings\n",
    "        embeddings = [\n",
    "            get_embeddings_from_ollama(modelname, chunk) for chunk in chunks\n",
    "        ]\n",
    "        # Save the embeddings to file\n",
    "        save_embeddings(filename, embeddings)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Simpan embedding ke file\n",
    "def save_embeddings(filename, embeddings):\n",
    "    if not os.path.exists(\"embeddings\"):\n",
    "        os.makedirs(\"embeddings\")\n",
    "    with open(f\"embeddings/{filename}.json\", \"w\") as f:\n",
    "        json.dump(embeddings, f)\n",
    "\n",
    "\n",
    "# # Mendapatkan embedding\n",
    "# def get_embeddings(filename, modelname, chunks):\n",
    "#     embeddings = [\n",
    "#         get_embeddings_from_ollama(modelname, chunk) for chunk in chunks\n",
    "#     ]\n",
    "#     save_embeddings(filename, embeddings)\n",
    "#     return embeddings\n",
    "\n",
    "# # Simpan embedding ke file\n",
    "# def save_embeddings(filename, embeddings):\n",
    "#     if not os.path.exists(\"embeddings\"):\n",
    "#         os.makedirs(\"embeddings\")\n",
    "#     with open(f\"embeddings/{filename}.json\", \"w\") as f:\n",
    "#         json.dump(embeddings, f)\n",
    "\n",
    "# Cosine similarity untuk menemukan kemiripan\n",
    "def find_most_similar(needle, haystack):\n",
    "    needle_norm = norm(needle)\n",
    "    similarity_scores = [\n",
    "        np.dot(needle, item) / (needle_norm * norm(item)) for item in haystack\n",
    "    ]\n",
    "    return sorted(zip(similarity_scores, range(len(haystack))), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "634ac4de-704d-4b68-89aa-61b54123184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding file data_api.json already exists. Loading embeddings...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  apa itu ojk?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "OJK! OJK stands for Otoritas Jasa Keuangan (Financial Services Authority), which is the main financial regulatory body in Indonesia. Its main objective is to maintain the stability and integrity of the financial system, as well as to protect consumers and ensure fair competition among financial institutions.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the assistant. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Fungsi utama\n",
    "def main():\n",
    "    SYSTEM_PROMPT = \"\"\"Anda adalah asisten yang membantu menjawab pertanyaan dengan bahasa Indonesia \n",
    "    dan berdasarkan cuplikan teks yang diberikan dalam konteks. Jawab hanya menggunakan konteks yang disediakan, \n",
    "    menjadi sesingkat mungkin. Jika Anda tidak yakin, katakan saja Anda tidak tahu.\n",
    "    Context:\n",
    "    \"\"\"\n",
    "\n",
    "    data_folder = \"data\"\n",
    "    all_paragraphs = []\n",
    "    filenames = []\n",
    "\n",
    "    # Iterasi semua file dalam folder data\n",
    "    for file in os.listdir(data_folder):\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        if file.lower().endswith((\".txt\", \".pdf\", \".docx\")):\n",
    "            paragraphs = parse_file(file_path)\n",
    "            all_paragraphs.extend(paragraphs)\n",
    "            filenames.append(file)\n",
    "\n",
    "    # Buat embedding\n",
    "    embeddings = get_embeddings(\"data_api\", \"nomic-embed-text\", all_paragraphs)\n",
    "    \n",
    "    while True:\n",
    "        prompt = input(\"Silakan tanya bosku? (ketik 'exit' untuk keluar) -> \")\n",
    "        \n",
    "        if prompt.lower() == \"exit\":\n",
    "            print(\"Exiting the assistant. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Mendapatkan embedding prompt dari Ollama\n",
    "        prompt_embedding = get_embeddings_from_ollama(\"nomic-embed-text\", prompt)\n",
    "\n",
    "        # Temukan paragraf yang paling mirip\n",
    "        most_similar_chunks = find_most_similar(prompt_embedding, embeddings)[:5]\n",
    "\n",
    "        # Persiapkan konteks untuk chat\n",
    "        context = \"\\n\".join(all_paragraphs[item[1]] for item in most_similar_chunks)\n",
    "        \n",
    "        # Kirim request chat ke Ollama\n",
    "        response = chat_with_ollama(\n",
    "            model=\"llama3\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT + context},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Print the full response\n",
    "        if response:\n",
    "            print(\"\\n\\n\")\n",
    "            print(response)  # Output the final model response\n",
    "        else:\n",
    "            print(\"Error or no response received.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ffdbf19-dd2d-4d75-abfc-a06d7c568fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"Anda adalah asisten yang membantu menjawab pertanyaan dengan bahasa Indonesia \n",
    "    dan berdasarkan cuplikan teks yang diberikan dalam konteks. Jawab hanya menggunakan konteks yang disediakan, \n",
    "    menjadi sesingkat mungkin. Jika Anda tidak yakin, katakan saja Anda tidak tahu.\n",
    "    Context:\n",
    "    \"\"\"\n",
    "\n",
    "data_folder = \"data\"\n",
    "all_paragraphs = []\n",
    "filenames = []\n",
    "\n",
    "# Iterasi semua file dalam folder data\n",
    "for file in os.listdir(data_folder):\n",
    "    file_path = os.path.join(data_folder, file)\n",
    "    if file.lower().endswith((\".txt\", \".pdf\", \".docx\")):\n",
    "        paragraphs = parse_file(file_path)\n",
    "        all_paragraphs.extend(paragraphs)\n",
    "        filenames.append(file)\n",
    "\n",
    "# Buat embedding\n",
    "embeddings = get_embeddings(\"data_api\", \"nomic-embed-text\", all_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e7748fe-6a72-4bb9-b6c3-41766155808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response is in NDJSON format.\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:31.3584388Z', 'message': {'role': 'assistant', 'content': 'Men'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:31.7903087Z', 'message': {'role': 'assistant', 'content': 'ur'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:32.251544Z', 'message': {'role': 'assistant', 'content': 'ut'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:32.813959Z', 'message': {'role': 'assistant', 'content': ' kont'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:33.2786261Z', 'message': {'role': 'assistant', 'content': 'eks'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:33.76007Z', 'message': {'role': 'assistant', 'content': ' yang'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:34.2252679Z', 'message': {'role': 'assistant', 'content': ' d'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:34.7815923Z', 'message': {'role': 'assistant', 'content': 'iber'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:35.2815612Z', 'message': {'role': 'assistant', 'content': 'ikan'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:35.7972621Z', 'message': {'role': 'assistant', 'content': ','}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:36.3100049Z', 'message': {'role': 'assistant', 'content': ' O'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:36.9275659Z', 'message': {'role': 'assistant', 'content': 'JK'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:37.4755777Z', 'message': {'role': 'assistant', 'content': ' sing'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:38.0211139Z', 'message': {'role': 'assistant', 'content': 'k'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:38.844012Z', 'message': {'role': 'assistant', 'content': 'atan'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:39.3996251Z', 'message': {'role': 'assistant', 'content': ' dari'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:39.9559531Z', 'message': {'role': 'assistant', 'content': ' O'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:40.5414952Z', 'message': {'role': 'assistant', 'content': 'tor'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:41.2094507Z', 'message': {'role': 'assistant', 'content': 'itas'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:41.769514Z', 'message': {'role': 'assistant', 'content': ' J'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:42.3104804Z', 'message': {'role': 'assistant', 'content': 'asa'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:42.9218706Z', 'message': {'role': 'assistant', 'content': ' Ke'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:43.4703803Z', 'message': {'role': 'assistant', 'content': 'u'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:43.9324692Z', 'message': {'role': 'assistant', 'content': 'angan'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:44.3737752Z', 'message': {'role': 'assistant', 'content': ' ('}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:44.8878488Z', 'message': {'role': 'assistant', 'content': 'Financial'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:45.3682094Z', 'message': {'role': 'assistant', 'content': ' Services'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:45.9091699Z', 'message': {'role': 'assistant', 'content': ' Authority'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:46.4494993Z', 'message': {'role': 'assistant', 'content': ').'}, 'done': False}\n",
      "Parsed JSON Data: {'model': 'llama3', 'created_at': '2024-12-04T10:15:47.0933759Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 30252983900, 'load_duration': 10244608800, 'prompt_eval_count': 1827, 'prompt_eval_duration': 4252885000, 'eval_count': 30, 'eval_duration': 15735689000}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prompt = input(\"Silakan tanya bosku? (ketik 'exit' untuk keluar) -> \")\n",
    "\n",
    "# if prompt.lower() == \"exit\":\n",
    "    # print(\"Exiting the assistant. Goodbye!\")\n",
    "    # break\n",
    "\n",
    "# Mendapatkan embedding prompt dari Ollama\n",
    "prompt_embedding = get_embeddings_from_ollama(\"nomic-embed-text\", \"apa itu ojk?\")\n",
    "\n",
    "# Temukan paragraf yang paling mirip\n",
    "most_similar_chunks = find_most_similar(prompt_embedding, embeddings)[:5]\n",
    "\n",
    "# Persiapkan konteks untuk chat\n",
    "context = \"\\n\".join(all_paragraphs[item[1]] for item in most_similar_chunks)\n",
    "\n",
    "# Kirim request chat ke Ollama\n",
    "response = chat_with_ollama(\n",
    "    model=\"llama3\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT + context},\n",
    "        {\"role\": \"user\", \"content\": \"apa itu ojk?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the full response\n",
    "# if response:\n",
    "    # print(\"\\n\\n\")\n",
    "    # print(response)  # Output the final model response\n",
    "# else:\n",
    "    # print(\"Error or no response received.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09f04871-e30c-48be-8b1b-2fd7d1eb7a01",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'status_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# response = requests.post(\"http://localhost:11434/api/generate\", json={\"model\": \"llama3\", \"prompt\": \"what is AI?\"})\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse Status Code:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse Content-Type:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/x-ndjson\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'status_code'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # response = requests.post(\"http://localhost:11434/api/generate\", json={\"model\": \"llama3\", \"prompt\": \"what is AI?\"})\n",
    "    \n",
    "    print(\"Response Status Code:\", response.status_code)\n",
    "    print(\"Response Content-Type:\", response.headers.get('Content-Type'))\n",
    "\n",
    "    if response.headers.get('Content-Type') == 'application/x-ndjson':\n",
    "        print(\"Response is in NDJSON format.\")\n",
    "        \n",
    "        full_response = \"\"  # Initialize an empty string to hold the full response\n",
    "        \n",
    "        for line in response.text.splitlines():\n",
    "            try:\n",
    "                # Parse each line as a JSON object\n",
    "                json_data = json.loads(line)\n",
    "                \n",
    "                # Append the 'response' part of each JSON object to the full response\n",
    "                full_response += json_data['response']\n",
    "                \n",
    "                # If the response is complete, print the full response\n",
    "                if json_data.get('done'):\n",
    "                    print(\"Full Response:\", full_response)\n",
    "                    break\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing line: {line}\")\n",
    "                print(f\"JSONDecodeError: {e}\")\n",
    "    else:\n",
    "        print(\"Response is not in NDJSON format.\")\n",
    "        print(response.json())\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3c4fa3a-9d83-4ff2-ba08-f50732c5fa87",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'status_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# response = requests.post(\"http://localhost:11434/api/generate\", json={\"model\": \"llama3\", \"prompt\": \"what is AI?\"})\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse Status Code:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse Content-Type:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/x-ndjson\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'status_code'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # response = requests.post(\"http://localhost:11434/api/generate\", json={\"model\": \"llama3\", \"prompt\": \"what is AI?\"})\n",
    "    \n",
    "    print(\"Response Status Code:\", response.status_code)\n",
    "    print(\"Response Content-Type:\", response.headers.get('Content-Type'))\n",
    "\n",
    "    if response.headers.get('Content-Type') == 'application/x-ndjson':\n",
    "        print(\"Response is in NDJSON format.\")\n",
    "        \n",
    "        full_response = \"\"  # Initialize an empty string to hold the full response\n",
    "        \n",
    "        for line in response.text.splitlines():\n",
    "            try:\n",
    "                # Parse each line as a JSON object\n",
    "                json_data = json.loads(line)\n",
    "                \n",
    "                # Print the entire json_data to inspect its structure\n",
    "                print(\"Parsed JSON Data:\", json_data)\n",
    "                \n",
    "                # Check if 'message' key exists and contains 'content'\n",
    "                if 'message' in json_data and 'content' in json_data['message']:\n",
    "                    # Append the 'content' part of each 'message' to the full response\n",
    "                    full_response += json_data['message']['content']\n",
    "                    \n",
    "                    # If the response is complete, print the full response\n",
    "                    if json_data.get('done'):\n",
    "                        print(\"Full Response:\", full_response)\n",
    "                        break\n",
    "                else:\n",
    "                    print(\"No 'message' or 'content' key in this JSON object:\", json_data)\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing line: {line}\")\n",
    "                print(f\"JSONDecodeError: {e}\")\n",
    "    else:\n",
    "        print(\"Response is not in NDJSON format.\")\n",
    "        print(response.json())\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
