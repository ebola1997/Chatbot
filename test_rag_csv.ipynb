{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cbe57cd-7d58-43ca-809a-8463e2ca655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "# Membaca file TXT\n",
    "def read_txt(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        return f.read()\n",
    "\n",
    "# Membaca file PDF\n",
    "def read_pdf(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        pdf_reader = PyPDF2.PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "# Membaca file DOCX\n",
    "def read_docx(filename):\n",
    "    doc = Document(filename)\n",
    "    text = \"\\n\".join(paragraph.text for paragraph in doc.paragraphs)\n",
    "    return text\n",
    "\n",
    "# Membaca file CSV\n",
    "# Membaca file CSV tanpa header dan mengisi NaN\n",
    "def read_csv(filename):\n",
    "    df = pd.read_csv(filename, header=None, delimiter=';', skip_blank_lines=True)\n",
    "    df = df.fillna(\"0\")  # Replace NaN with \"0\"\n",
    "    text = \"\"\n",
    "    \n",
    "    # Loop through the rows\n",
    "    for idx, row in df.iterrows():\n",
    "        if idx >= 1:  # Ensure that idx is an integer\n",
    "            text += f\"'{idx}. \" + \", \".join(str(value) for value in row.values) + \"\\n\"\n",
    "        else:\n",
    "            # If it's the first row (header row), don't add an index number\n",
    "            text += \"Ini adalah data csv dengan delimter (,)\\n\" + \", \".join(str(value) for value in row.values) + \"\\n\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Membaca file Excel (.xlsx)\n",
    "def read_xlsx(filename):\n",
    "    df = pd.read_excel(filename)\n",
    "    text = \"\"\n",
    "    for index, row in df.iterrows():\n",
    "        text += \" \".join(str(value) for value in row.values) + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Mendapatkan paragraf dari semua file\n",
    "def parse_file(filename):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        content = read_txt(filename)\n",
    "    elif filename.endswith(\".pdf\"):\n",
    "        content = read_pdf(filename)\n",
    "    elif filename.endswith(\".docx\"):\n",
    "        content = read_docx(filename)\n",
    "    elif filename.endswith(\".csv\"):\n",
    "        content = read_csv(filename)\n",
    "    elif filename.endswith(\".xlsx\"):  # Menambahkan pengecekan untuk file Excel\n",
    "        content = read_xlsx(filename)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {filename}\")\n",
    "    \n",
    "    paragraphs = []\n",
    "    buffer = []\n",
    "    for line in content.splitlines():\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            buffer.append(line)\n",
    "        elif len(buffer):\n",
    "            paragraphs.append(\" \".join(buffer))\n",
    "            buffer = []\n",
    "    if len(buffer):\n",
    "        paragraphs.append(\" \".join(buffer))\n",
    "    return paragraphs\n",
    "\n",
    "# Simpan embedding ke file\n",
    "def save_embeddings(filename, embeddings):\n",
    "    if not os.path.exists(\"embeddings\"):\n",
    "        os.makedirs(\"embeddings\")\n",
    "    with open(f\"embeddings/{filename}.json\", \"w\") as f:\n",
    "        json.dump(embeddings, f)\n",
    "\n",
    "# Memuat embedding dari file\n",
    "def load_embeddings(filename):\n",
    "    if not os.path.exists(f\"embeddings/{filename}.json\"):\n",
    "        return False\n",
    "    with open(f\"embeddings/{filename}.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Mendapatkan embedding\n",
    "def get_embeddings(filename, modelname, chunks):\n",
    "    if (embeddings := load_embeddings(filename)) is not False:\n",
    "        return embeddings\n",
    "    embeddings = [\n",
    "        ollama.embeddings(model=modelname, prompt=chunk)[\"embedding\"]\n",
    "        for chunk in chunks\n",
    "    ]\n",
    "    \n",
    "    # Reduksi dimensi jika diperlukan (misalnya PCA)\n",
    "    reduced_embeddings = reduce_embeddings_dimension(embeddings)\n",
    "    \n",
    "    save_embeddings(filename, reduced_embeddings)\n",
    "    return reduced_embeddings\n",
    "\n",
    "# Reduksi Dimensi dengan PCA (jika diperlukan)\n",
    "def reduce_embeddings_dimension(embeddings):\n",
    "    embeddings_array = np.array(embeddings)\n",
    "    \n",
    "    # Mengecek dimensi pertama\n",
    "    if embeddings_array.shape[1] > 768:  # Jika dimensi lebih besar dari 768 (misalnya 4096)\n",
    "        pca = PCA(n_components=768)  # Mengurangi dimensi ke 768\n",
    "        embeddings_array = pca.fit_transform(embeddings_array)  # Reduksi dimensi\n",
    "        print(f\"Reduksi dimensi menjadi: {embeddings_array.shape}\")\n",
    "    \n",
    "    return embeddings_array.tolist()  # Mengembalikan sebagai list jika diperlukan\n",
    "\n",
    "# Cosine similarity untuk menemukan kemiripan\n",
    "def find_most_similar(needle, haystack):\n",
    "    needle_norm = norm(needle)\n",
    "    similarity_scores = [\n",
    "        np.dot(needle, item) / (needle_norm * norm(item)) for item in haystack\n",
    "    ]\n",
    "    return sorted(zip(similarity_scores, range(len(haystack))), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e3c646-8112-4c9f-af95-d5fb154566e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subfolders in the `data` directory\n",
    "data_root = \"data/\"\n",
    "# subfolders = [f for f in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, f))]\n",
    "\n",
    "# Streamlit select box to choose the folder\n",
    "# selected_folder = st.selectbox(\"Pilih folder dataset:\", subfolders)\n",
    "\n",
    "# Load or process embeddings\n",
    "data_folder = os.path.join(data_root, \"CSV\")\n",
    "all_paragraphs = []\n",
    "filenames = []\n",
    "\n",
    "for file in os.listdir(data_folder):\n",
    "    file_path = os.path.join(data_folder, file)\n",
    "    if file.lower().endswith((\".txt\", \".pdf\", \".docx\", \".csv\")):\n",
    "        paragraphs = parse_file(file_path)\n",
    "        all_paragraphs.extend(paragraphs)\n",
    "        filenames.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9dd25ef-8813-47bb-83dd-7640869d9d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Ini adalah data csv dengan delimter (,) Nama, total, diambil, sisa, cuti timbul, jumlah cuti bersama, jumlah cuti tahunan sebelumnya '1. Arselan Utama, 18, 3, 6, 15, 9, 3 '2. Windra Fitri Rahman, 15, 0, 6, 15, 9, 0 '3. Fatkhan Nugroho, 15, 0, 6, 15, 9, 0 '4. Ari Budiyanto, 15, 0, 6, 15, 9, 0 '5. Ridho Yuriansyah Putra, 19, 4, 6, 15, 9, 4 '6. Ferry Seloria, 21, 8, 4, 15, 9, 6 '7. Imaddudin Ishak Saifuddin, 15, 5, 1, 15, 9, 5 '8. Ramdani, 15, 0, 6, 15, 9, 0 '9. Roni Saputra, 15, 0, 6, 15, 9, 0 '10. Ahmad Taqyuddin, 15, 0, 6, 15, 9, 0 '11. Denis HP. Sarumpaet, 25, 8, 8, 21, 9, 4 '12. Rhisa Meidilla Sari, 15, 3, 3, 15, 9, 0 '13. Winda Angelina Lala, 15, 2, 4, 15, 9, 0 '14. Ega Nofiardi, 25, 9, 7, 16, 9, 9 '15. Akbar, 25, 5, 11, 24, 9, 1 '16. Andri Mardani, 25, 7, 9, 18, 9, 7 '17. Teddy Olgaraditya, 20, 7, 4, 15, 9, 5 '18. Mohammad Ichsan Andrian, 18, 6, 3, 15, 9, 3 '19. Muhammad Bahrul Ulum, 18, 3, 6, 15, 9, 3 '20. Hafiizh Septian Pristanto, 18, 3, 6, 15, 9, 3 '21. Mohamad Rosid, 15, 0, 6, 15, 9, 0 '22. Irvan Amirudin, 21, 6, 6, 16, 9, 5 '23. Zubair, 18, 3, 6, 15, 9, 3 '24. Ardi Nugraha, 22, 9, 4, 21, 9, 1 '25. Teguh Prasetyo, 18, 3, 6, 15, 9, 3 '26. Fikri Rama Singgih, 19, 4, 6, 15, 9, 4 '27. Indryana Fitrinda, 18, 7, 2, 15, 9, 3 '28. Rinaldo Anugrah Wahyuda, 21, 6, 6, 15, 9, 6 '29. Indra Cahaya Wardana, 37, 27, 1, 15, 9, 22 '30. Dwi Akmalludin, 15, 0, 6, 15, 9, 0 '31. Ayu Rejeki Widia Sari, 16, 4, 3, 15, 9, 1 '32. Budi Supratman, 19, 7, 3, 16, 9, 3 '33. Alfip Razeb Pasya, 19, 5, 5, 15, 9, 4 '34. Engbi Setiawan, 20, 5, 6, 15, 9, 5 '35. Whindy Pradita Septiani, 16, 2, 5, 15, 9, 1 '36. Freenanda Richard Bolang, 19, 7, 3, 16, 9, 3 '37. Mohammad Kurnia Putra, 15, 1, 5, 15, 9, 0 '38. Ali Iskandar, 22, 5, 8, 21, 9, 1 '39. Priska Martina Mailangkay, 15, 1, 5, 15, 9, 0 '40. Taufiqurrohman, 15, 1, 5, 15, 9, 0 '41. Muhamad Yayan, 15, 0, 6, 15, 9, 0 '42. Yusri Akmal, 15, 0, 6, 15, 9, 0 '43. Ni Wayan Surina, 15, 0, 6, 15, 9, 0 '44. Andrei Oktavian Silitonga, 12, 0, 4, 12, 8, 0 '45. Salman Alfarisi, 12, 1, 4, 12, 7, 0 '46. Anggi Audia Esmeralda, 10, 0, 3, 10, 7, 0 '47. Muhamad Ritzky, 9, 0, 7, 9, 2, 0 '48. Anguditomo, 8, 0, 7, 8, 1, 0 '49. Rafael Richie, 9, 0, 8, 9, 1, 0 '50. Hafizh Umar Syafiqh, 2, 0, 2, 2, 0, 0 '51. Angries, 1, 0, 1, 1, 0, 0 '52. Mohammad Rayhan, 1, 0, 1, 1, 0, 0\"]\n"
     ]
    }
   ],
   "source": [
    "print(all_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65ad25ab-8ad4-42aa-91bd-00db5f41bfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  berapa cuti freenanda bolang?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Maaf, saya tidak tahu.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  bagaimana dengan cuti Arselan Utama\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Berdasarkan data cuti PINET, Arselan Utama memiliki total cuti 18 hari, diambil 3 hari, sisanya 15 hari, cuti timbul 9 hari, dan jumlah cuti bersama 3 hari.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  bagaimana dengan cuti Fikri Rama\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Menurut data karyawan PINET, Fikri Rama Singgih memiliki jumlah cuti sebesar 19 dengan diambil 4 dan sisa 15.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  bagaimana dengan cuti Freenanda bolang\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Menurut data, Freenanda Richard Bolang memiliki total cuti 19 hari, diambil 7 hari, dan sisanya 15 hari.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the assistant. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    SYSTEM_PROMPT = \"\"\"You are an assistant that answers questions only in Bahasa Indonesia. \n",
    "    Your answers must be based solely on the provided context extracted from the documents. \n",
    "    If the answer cannot be determined from the context, respond with \"Maaf, saya tidak tahu.\" \n",
    "    Do not include any information outside of the given context, and strictly reply in Bahasa Indonesia.\n",
    "\n",
    "    Context:\n",
    "    \"\"\"\n",
    "\n",
    "    # Load subfolders in the `data` directory\n",
    "    # Load subfolders in the `data` directory\n",
    "    data_root = \"data/\"\n",
    "    # subfolders = [f for f in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, f))]\n",
    "    \n",
    "    # Streamlit select box to choose the folder\n",
    "    # selected_folder = st.selectbox(\"Pilih folder dataset:\", subfolders)\n",
    "    \n",
    "    # Load or process embeddings\n",
    "    data_folder = os.path.join(data_root, \"Test\")\n",
    "    all_paragraphs = []\n",
    "    filenames = []\n",
    "    \n",
    "    for file in os.listdir(data_folder):\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        if file.lower().endswith((\".txt\", \".pdf\", \".docx\", \".csv\")):\n",
    "            paragraphs = parse_file(file_path)\n",
    "            all_paragraphs.extend(paragraphs)\n",
    "            filenames.append(file)\n",
    "\n",
    "\n",
    "    folder_name = os.path.basename(data_folder)\n",
    "\n",
    "    # Buat nama file embeddings berdasarkan nama folder\n",
    "    embeddings_filename = f\"data_embeddings_{folder_name}\"\n",
    "    # Buat embedding\n",
    "    embeddings = get_embeddings(embeddings_filename, \"nomic-embed-text\", all_paragraphs)\n",
    "\n",
    "    while True:\n",
    "        prompt = input(\"Silakan tanya bosku? (ketik 'exit' untuk keluar) -> \")\n",
    "        \n",
    "        if prompt.lower() == \"exit\":\n",
    "            print(\"Exiting the assistant. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        prompt_embedding = ollama.embeddings(model=\"nomic-embed-text\", prompt=prompt)[\"embedding\"]\n",
    "        \n",
    "        # Reduksi dimensi jika perlu pada prompt embedding (jika diperlukan)\n",
    "        prompt_embedding = reduce_embeddings_dimension([prompt_embedding])[0]  # Reduksi menjadi 768 dimensi\n",
    "\n",
    "        most_similar_chunks = find_most_similar(prompt_embedding, embeddings)[:10]\n",
    "\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": SYSTEM_PROMPT\n",
    "                    + \"\\n\".join(all_paragraphs[item[1]] for item in most_similar_chunks),\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        print(response[\"message\"][\"content\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "43110258-102a-4706-911c-010f26ff3da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV has been successfully converted to data\\Test\\output2.txt.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def csv_to_txt(input_filename, output_filename):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_filename, header=0)  # Assumes first row is the header\n",
    "    df = df.fillna(\"0\")  # Replace NaN with \"0\"\n",
    "\n",
    "    # Open the output .txt file for writing\n",
    "    with open(output_filename, 'w', encoding=\"utf-8\") as txt_file:\n",
    "        # Write the header (column names)\n",
    "        headers = \", \".join(df.columns)\n",
    "        txt_file.write(f\"{headers}\\n\")\n",
    "        \n",
    "        # Write the rows with index\n",
    "        for idx, row in df.iterrows():\n",
    "            row_data = \", \".join(str(value) for value in row.values)\n",
    "            txt_file.write(f\"{idx + 1}. {row_data}\\n\")\n",
    "    \n",
    "    print(f\"CSV has been successfully converted to {output_filename}.\")\n",
    "\n",
    "# Example usage:\n",
    "input_csv = \"data\\CSV\\data_dummy.csv\"  # Path to your CSV file\n",
    "output_txt = \"data\\Test\\output2.txt\"  # Desired path for the output TXT file\n",
    "\n",
    "csv_to_txt(input_csv, output_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5ba197bc-372d-4ec6-a624-8d1171502bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV dengan data dummy telah dibuat.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import faker\n",
    "\n",
    "# Membuat instance dari Faker untuk menghasilkan data acak\n",
    "fake = faker.Faker()\n",
    "\n",
    "# Menyiapkan data dummy\n",
    "data = []\n",
    "for _ in range(50):\n",
    "    nama = fake.name()\n",
    "    gaji = random.randint(5000000, 15000000)  # Gaji acak antara 3 juta sampai 15 juta\n",
    "    gender = random.choice([\"Laki\", \"Perempuan\", \"Non Binary\", \"Others\"])\n",
    "    data.append([nama, gaji, jabatan])\n",
    "\n",
    "# Membuat DataFrame dari data dummy\n",
    "df = pd.DataFrame(data, columns=[\"Nama\", \"Gaji\", \"Jabatan\"])\n",
    "\n",
    "# Menyimpan ke CSV dengan delimiter ;\n",
    "df.to_csv(\"data\\CSV\\data_dummy.csv\", sep=\";\", index=False)\n",
    "\n",
    "print(\"CSV dengan data dummy telah dibuat.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
