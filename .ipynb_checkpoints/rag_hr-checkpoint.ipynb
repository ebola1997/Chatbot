{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880ac164-0276-4d7b-aae9-a5a10cd33985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "from sklearn.decomposition import PCA  # Menambahkan PCA untuk reduksi dimensi jika perlu\n",
    "\n",
    "# Membaca file TXT\n",
    "def read_txt(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        return f.read()\n",
    "\n",
    "# Membaca file PDF\n",
    "def read_pdf(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        pdf_reader = PyPDF2.PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "# Membaca file DOCX\n",
    "def read_docx(filename):\n",
    "    doc = Document(filename)\n",
    "    text = \"\\n\".join(paragraph.text for paragraph in doc.paragraphs)\n",
    "    return text\n",
    "\n",
    "# Mendapatkan paragraf dari semua file\n",
    "def parse_file(filename):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        content = read_txt(filename)\n",
    "    elif filename.endswith(\".pdf\"):\n",
    "        content = read_pdf(filename)\n",
    "    elif filename.endswith(\".docx\"):\n",
    "        content = read_docx(filename)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {filename}\")\n",
    "    \n",
    "    paragraphs = []\n",
    "    buffer = []\n",
    "    for line in content.splitlines():\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            buffer.append(line)\n",
    "        elif len(buffer):\n",
    "            paragraphs.append(\" \".join(buffer))\n",
    "            buffer = []\n",
    "    if len(buffer):\n",
    "        paragraphs.append(\" \".join(buffer))\n",
    "    return paragraphs\n",
    "\n",
    "# Simpan embedding ke file\n",
    "def save_embeddings(filename, embeddings):\n",
    "    if not os.path.exists(\"embeddings\"):\n",
    "        os.makedirs(\"embeddings\")\n",
    "    with open(f\"embeddings/{filename}.json\", \"w\") as f:\n",
    "        json.dump(embeddings, f)\n",
    "\n",
    "# Memuat embedding dari file\n",
    "def load_embeddings(filename):\n",
    "    if not os.path.exists(f\"embeddings/{filename}.json\"):\n",
    "        return False\n",
    "    with open(f\"embeddings/{filename}.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Mendapatkan embedding\n",
    "def get_embeddings(filename, modelname, chunks):\n",
    "    if (embeddings := load_embeddings(filename)) is not False:\n",
    "        return embeddings\n",
    "    embeddings = [\n",
    "        ollama.embeddings(model=modelname, prompt=chunk)[\"embedding\"]\n",
    "        for chunk in chunks\n",
    "    ]\n",
    "    \n",
    "    # Reduksi dimensi jika diperlukan (misalnya PCA)\n",
    "    reduced_embeddings = reduce_embeddings_dimension(embeddings)\n",
    "    \n",
    "    save_embeddings(filename, reduced_embeddings)\n",
    "    return reduced_embeddings\n",
    "\n",
    "# Reduksi Dimensi dengan PCA (jika diperlukan)\n",
    "def reduce_embeddings_dimension(embeddings):\n",
    "    embeddings_array = np.array(embeddings)\n",
    "    \n",
    "    # Mengecek dimensi pertama\n",
    "    if embeddings_array.shape[1] > 768:  # Jika dimensi lebih besar dari 768 (misalnya 4096)\n",
    "        pca = PCA(n_components=768)  # Mengurangi dimensi ke 768\n",
    "        embeddings_array = pca.fit_transform(embeddings_array)  # Reduksi dimensi\n",
    "        print(f\"Reduksi dimensi menjadi: {embeddings_array.shape}\")\n",
    "    \n",
    "    return embeddings_array.tolist()  # Mengembalikan sebagai list jika diperlukan\n",
    "\n",
    "# Cosine similarity untuk menemukan kemiripan\n",
    "def find_most_similar(needle, haystack):\n",
    "    needle_norm = norm(needle)\n",
    "    similarity_scores = [\n",
    "        np.dot(needle, item) / (needle_norm * norm(item)) for item in haystack\n",
    "    ]\n",
    "    return sorted(zip(similarity_scores, range(len(haystack))), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c206c0-6425-4071-bc56-fee1f7cf7ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  apa saja isi point yg terdapat pada dokumen Cara Akses Laporan Keuangan?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Dalam dokumen \"Cara Akses Laporan Keuangan\", terdapat beberapa isi point yang meliputi:\n",
      "\n",
      "1. Kapan laporan keuangan dapat diakses\n",
      "2. Siapa yang bisa mengakses laporan keuangan departemen\n",
      "3. Apa itu laporan keuangan departemen\n",
      "\n",
      "Selain itu, dokumen tersebut juga menjelaskan bagaimana cara akses laporan keuangan yaitu melalui Portal Karyawan Askrindo Syariah di intranet dan syarat-syarat untuk mengaksesnya.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  lalu apa saja 6 pertanyaan yg ada pada dokumen cara akses laporan keuangan?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Dokumen \"Cara Akses Laporan Keuangan\" memiliki enam pertanyaan sebagai berikut:\n",
      "\n",
      "1. Siapa yang bisa mengakses laporan keuangan departemen?\n",
      "2. Kapan laporan keuangan dapat diakses?\n",
      "3. Apa itu laporan keuangan departemen?\n",
      "4. Bagaimana cara mengakses laporan keuangan departemen?\n",
      "5. (Tidak ada pertanyaan lain)\n",
      "6. (Tidak ada pertanyaan lain)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  lalu siapa itu fikri rama singgih?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Maaf, saya tidak tahu. Nama Fikri Rama Singgih tidak ada dalam konteks yang diberikan.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  bagaimana dengan fikri rama?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Maaf, saya tidak tahu. Informasi tentang Fikri Rama tidak terdapat dalam konteks tersebut.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  lalu apa saja isi konteks yg anda pahami atau dokumen apa saja yg anda pahami?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Saya pahami dokumen tentang prosedur penggajian karyawan, aplikasi mobile yang digunakan untuk mengakses slip gaji, dan laporan keuangan departemen. Dokumen tersebut juga berisi informasi tentang langkah-langkah karyawan dalam mengakses aplikasi dan portal karyawan Askrindo Syariah.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  kalau begitu bagaimana dengan fikri apakah tidak ada data fikri?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Maaf, saya tidak tahu. Tidak ada informasi tentang Fikri dalam konteks yang diberikan.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  anda kenal fikri? coba jabarkan dia seperti apa?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Maaf, saya tidak tahu. Context kita hanya berbicara tentang uang dinas, laporan keuangan, dan aplikasi mobile untuk mengakses slip gaji. Tidak ada informasi tentang seseorang bernama Fikri.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Silakan tanya bosku? (ketik 'exit' untuk keluar) ->  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the assistant. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Fungsi utama\n",
    "def main():\n",
    "    SYSTEM_PROMPT = \"\"\"You are an assistant that answers questions only in Bahasa Indonesia. \n",
    "    Your answers must be based solely on the provided context extracted from the documents. \n",
    "    If the answer cannot be determined from the context, respond with \"Maaf, saya tidak tahu.\" \n",
    "    Do not include any information outside of the given context, and strictly reply in Bahasa Indonesia.\n",
    "\n",
    "    Context:\n",
    "    \"\"\"\n",
    "\n",
    "    data_folder = \"data/Finance\"\n",
    "    all_paragraphs = []\n",
    "    filenames = []\n",
    "\n",
    "    # Iterasi semua file dalam folder data\n",
    "    for file in os.listdir(data_folder):\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        if file.lower().endswith((\".txt\", \".pdf\", \".docx\")):\n",
    "            paragraphs = parse_file(file_path)\n",
    "            all_paragraphs.extend(paragraphs)\n",
    "            filenames.append(file)\n",
    "\n",
    "    # Buat embedding\n",
    "    embeddings = get_embeddings(\"data_embeddings_Finance\", \"nomic-embed-text\", all_paragraphs)\n",
    "\n",
    "    while True:\n",
    "        prompt = input(\"Silakan tanya bosku? (ketik 'exit' untuk keluar) -> \")\n",
    "        \n",
    "        if prompt.lower() == \"exit\":\n",
    "            print(\"Exiting the assistant. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        prompt_embedding = ollama.embeddings(model=\"nomic-embed-text\", prompt=prompt)[\"embedding\"]\n",
    "        \n",
    "        # Reduksi dimensi jika perlu pada prompt embedding (jika diperlukan)\n",
    "        prompt_embedding = reduce_embeddings_dimension([prompt_embedding])[0]  # Reduksi menjadi 768 dimensi\n",
    "\n",
    "        most_similar_chunks = find_most_similar(prompt_embedding, embeddings)[:5]\n",
    "\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": SYSTEM_PROMPT\n",
    "                    + \"\\n\".join(all_paragraphs[item[1]] for item in most_similar_chunks),\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        print(response[\"message\"][\"content\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
